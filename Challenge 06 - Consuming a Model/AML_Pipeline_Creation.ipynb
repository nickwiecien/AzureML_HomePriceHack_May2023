{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "485e0c8e-a585-49ea-b8d7-68292962ed55",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b532d3-932e-42e5-9164-7fcc53b9d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Datastore, Environment, Dataset\n",
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import PipelineParameter, PipelineData\n",
    "from azureml.data.output_dataset_config import OutputTabularDatasetConfig, OutputDatasetConfig, OutputFileDatasetConfig\n",
    "from azureml.data.datapath import DataPath\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c5d433-3552-44c4-9412-c463b8762280",
   "metadata": {},
   "source": [
    "## Connect to Azure ML Workspace using the AML SDK\n",
    "The code snippet below retrieves a reference to your AML workspace - you can interact directly with resources in your workspace via the SDK, similar to how you can use the Studio UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84203bef-9c85-4b65-a0e9-efba244b627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cde380-179a-4873-bd5a-f655dd8db8ec",
   "metadata": {},
   "source": [
    "## Create an Experiment\n",
    "Experiments are logical containers of script runs which can hold different metrics and experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fce882d-720d-4477-a007-0f7b9e88dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "# TO-DO:\n",
    "# Update the experiment_name variable below to 'yourinitials_batch_scoring_pipeline_run`\n",
    "\n",
    "experiment_name = \"<YOUR-EXPERIMENT-NAME>\"\n",
    "experiment = Experiment(ws, experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33409826-b8cf-4e6f-b946-5e24ff84bbf3",
   "metadata": {},
   "source": [
    "## Retrieve a Reference to Compute Cluster\n",
    "Get a pointer to your created AML Compute Cluster (`cpucluster-yourinitials`). You will use this as the compute engine for executing your script run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1c2bf9-685b-401b-92a5-7a2999cd292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "# TO-DO:\n",
    "# Update the cpu_cluster_name variable below to the name of the cluster you previously created (cpucluster-yourinitials)\n",
    "\n",
    "cpu_cluster_name = \"<YOUR-COMPUTE-TARGET-NAME>\"\n",
    "cpu_cluster = ComputeTarget(ws, cpu_cluster_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2387ecf-9977-4b2c-8b79-3272759ca9f7",
   "metadata": {},
   "source": [
    "## Retrieve Curated AutoML Environment from Azure ML Workspace\n",
    "AML environments are reusable software environments that contain dependencies for model training/inferencing operations. These environments can be manually created, packaged into reusable docker containers, and then leveraged time and again for different MLOps activities.\n",
    "\n",
    "AML supports a number of curated environments for popular open-source ML frameworks (TensorFlow, Pytorch, Scikit, etc.) including one for AutoML (AzureML-AutoML) which we will leverage here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f93523f-b32b-4418-b67f-c22a1ef9f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "env = Environment.get(ws, 'AzureML-AutoML')\n",
    "\n",
    "run_config = RunConfiguration()\n",
    "run_config.environment = env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f83d48-28e4-4bc8-adee-58cf7cd1e37b",
   "metadata": {},
   "source": [
    "## Define Pipeline Parameters\n",
    "`PipelineParameter` objects serve as variable inputs to an Azure ML pipeline and can be specified at runtime. Update the pipeline parameters below to include parameters for the following variables:\n",
    "\n",
    "| Pipeline Parameter Name |  Description |\n",
    "|-------------------------|--------------|\n",
    "| `model_name`  | The name of the model in your model registry which you will use for batch scoring (if you have completed Challenge 5 this should be the same value  you used for the `model_name` parameter there) |\n",
    "| `datastore_name` | The name of the datastore where your output dataset will be saved |\n",
    "| `inferencing_dataset_name` | The name of the test dataset you created ('<i>YOURINITIALS</i>-HOME-PRICE-TEST-DATA') |\n",
    "| `scored_dataset_name` | Name of the dataset to be created upon pipeline execution with your scored home price results |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ecea2c-16e0-4893-81fd-4f16a3944ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO: Update the default values of the PipelineParameters below according to the description in the table above\n",
    "\n",
    "model_name = PipelineParameter(name='model_name', default_value='')\n",
    "datastore_name = PipelineParameter(name='datastore_name', default_value='')\n",
    "inferencing_dataset_name = PipelineParameter(name='inferencing_dataset_name', default_value='')\n",
    "scored_dataset_name = PipelineParameter(name='scored_dataset_name', default_value='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c94f139-48ae-439d-86a8-82b0f544207f",
   "metadata": {},
   "source": [
    "## Define Pipeline Steps\n",
    "The pipeline below consists of a single step which executes an associated python script located in the `./pipeline_script_steps`. Here, we call `batch_score_data.py` and retrieve a dataset from your AML workspace (referenced by  `inferencing_dataset_name`), load your ML model (referenced by `model_name`) into code, make predictions over the loaded data, and then save that as a new dataset (referenced by `scored_dataset_name` and `datastore_name`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2216d5f9-345b-4447-a162-4caff73e9cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get inferencing data from AML-linked datastore\n",
    "# Use your trained model to make predictions over your data\n",
    "batch_score_data_step = PythonScriptStep(\n",
    "    name='Batch Score Home Data',\n",
    "    script_name='batch_score_data.py',\n",
    "    arguments =['--model_name', model_name,\n",
    "                '--datastore_name', datastore_name,\n",
    "                '--inferencing_dataset_name', inferencing_dataset_name,\n",
    "                '--scored_dataset_name', scored_dataset_name\n",
    "               ],\n",
    "    compute_target=cpu_cluster,\n",
    "    source_directory='./pipeline_step_scripts',\n",
    "    allow_reuse=False,\n",
    "    runconfig=run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3d35ec-7278-4f64-8ccd-bca6475997b0",
   "metadata": {},
   "source": [
    "## Create Pipeline and Run\n",
    "Create an Azure ML Pipeline by specifying the steps to be executed then submit a new run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa15b3-d304-40cb-8070-b090aca3e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(ws, [batch_score_data_step])\n",
    "run = experiment.submit(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
